%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for AIMachine at 2021-05-25 14:55:08 +0200


%% Saved with string encoding Unicode (UTF-8)

@article{scikit-image,
 title = {scikit-image: image processing in {P}ython},
 author = {van der Walt, {S}t\'efan and {S}ch\"onberger, {J}ohannes {L}. and
           {Nunez-Iglesias}, {J}uan and {B}oulogne, {F}ran\c{c}ois and {W}arner,
           {J}oshua {D}. and {Y}ager, {N}eil and {G}ouillart, {E}mmanuelle and
           {Y}u, {T}ony and the scikit-image contributors},
 year = {2014},
 month = {6},
 keywords = {Image processing, Reproducible research, Education,
             Visualization, Open source, Python, Scientific programming},
 volume = {2},
 pages = {e453},
 journal = {PeerJ},
 issn = {2167-8359},
 doi = {10.7717/peerj.453}
}

@inproceedings{Ronn2015,
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
	address = {Cham},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015},
	date-added = {2021-05-24 16:43:11 +0200},
	date-modified = {2021-05-24 16:43:11 +0200},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	isbn = {978-3-319-24574-4},
	pages = {234--241},
	publisher = {Springer International Publishing},
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	year = {2015}}

@article{Murray2008,
	abstract = {Automated imaging of the Caenorhabditis elegans embryo now allows monitoring of the timing and relative expression of individual reporter genes at single-cell resolution over almost all of embryonic development. Future systematic analysis could be used to reveal gene expression patterns of every cell during development.},
	author = {Murray, John Isaac and Bao, Zhirong and Boyle, Thomas J and Boeck, Max E and Mericle, Barbara L and Nicholas, Thomas J and Zhao, Zhongying and Sandel, Matthew J and Waterston, Robert H},
	da = {2008/08/01},
	date-added = {2021-05-24 15:00:27 +0200},
	date-modified = {2021-05-24 15:00:59 +0200},
	doi = {10.1038/nmeth.1228},
	id = {Murray2008},
	isbn = {1548-7105},
	journal = {Nature Methods},
	number = {8},
	pages = {703--709},
	title = {Automated analysis of embryonic gene expression with cellular resolution in C. elegans},
	ty = {JOUR},
	volume = {5},
	year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1038/nmeth.1228}}

@misc{Celegans,
	date-added = {2021-05-24 14:58:34 +0200},
	date-modified = {2021-05-24 15:00:22 +0200},
	howpublished = {http://celltrackingchallenge.net/3d-datasets/},
	title = {Waterston Lab, University of Washington, Seattle, WA, USA}}

@article{Lucy74,
	author = {L.B. Lucy},
	date-added = {2021-05-23 19:44:07 +0200},
	date-modified = {2021-05-23 19:45:40 +0200},
	doi={10.1086/111605},
	journal = {The Astronomical Journal 7},
	pages = {745},
	title = {An iterative technique for the rectification of observed distributions},
	volume = {79},
	year = {1974}}

@article{Richardson72,
	abstract = {An iterative method of restoring degraded images was developed by treating images, point spread functions, and degraded images as probability-frequency functions and by applying Bayes's theorem. The method functions effectively in the presence of noise and is adaptable to computer operation.},
	author = {William Hadley Richardson},
	date-added = {2021-05-23 19:35:34 +0200},
	date-modified = {2021-05-23 19:41:03 +0200},
	doi = {10.1364/JOSA.62.000055},
	journal = {J. Opt. Soc. Am.},
	keywords = {Arrays; Deconvolution; Image processing; Point spread function},
	month = {Jan},
	number = {1},
	pages = {55--59},
	publisher = {OSA},
	title = {Bayesian-Based Iterative Method of Image Restoration$\ast$},
	volume = {62},
	year = {1972},
	Bdsk-Url-1 = {http://www.osapublishing.org/abstract.cfm?URI=josa-62-1-55},
	Bdsk-Url-2 = {https://doi.org/10.1364/JOSA.62.000055}}

@misc{Fijiwiki,
	author = {Jean-Yves Tinevez},
	date-added = {2021-05-23 13:18:06 +0200},
	date-modified = {2021-05-23 13:20:01 +0200},
	howpublished = {https://imagej.net/TrackMate},
	rss-description = {https://imagej.net/TrackMate},
	title = {Trackmate manual}}

@misc{Github2021,
	title = {https://github.com/kapoorlab/VollSeg, https://github.com/kapoorlab/NapaTrackMater, https://github.com/kapoorlab/BTrackMate}}

@article{Jones2001,
	author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu},
	month = {01},
	title = {SciPy: Open Source Scientific Tools for Python},
	year = {2001}}

@article{Kuhn1955,
	abstract = {Abstract Assuming that numerical scores are available for the performance of each of n persons on each of n jobs, the ``assignment problem'' is the quest for an assignment of persons to jobs so that the sum of the n scores so obtained is as large as possible. It is shown that ideas latent in the work of two Hungarian mathematicians may be exploited to yield a new method of solving this problem.},
	author = {Kuhn, H. W.},
	doi = {10.1002/nav.3800020109},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/nav.3800020109},
	journal = {Naval Research Logistics Quarterly},
	number = {1‚Äê2},
	pages = {83-97},
	title = {The Hungarian method for the assignment problem},
	volume = {2},
	year = {1955},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nav.3800020109},
	Bdsk-Url-2 = {https://doi.org/10.1002/nav.3800020109}}

@article{Weigert2017,
	abstract = {Fluorescence microscopy is a key driver of discoveries in the life-sciences, with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample. These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth. In this work we show how deep learning enables biological observations beyond the physical limitations of microscopes. On seven concrete examples we illustrate how microscopy images can be restored even if 60-fold fewer photons are used during acquisition, how isotropic resolution can be achieved even with a 10-fold under-sampling along the axial direction, and how diffraction-limited structures can be resolved at 20-times higher frame-rates compared to state-of-the-art methods. All developed image restoration methods are freely available as open source software.},
	author = {Weigert, Martin and Schmidt, Uwe and Boothe, Tobias and M{\"u}ller, Andreas and Dibrov, Alexandr and Jain, Akanksha and Wilhelm, Benjamin and Schmidt, Deborah and Broaddus, Coleman and Culley, Si{\^a}n and Rocha-Martins, Mauricio and Segovia-Miranda, Fabi{\'a}n and Norden, Caren and Henriques, Ricardo and Zerial, Marino and Solimena, Michele and Rink, Jochen and Tomancak, Pavel and Royer, Loic and Jug, Florian and Myers, Eugene W.},
	doi = {10.1101/236463},
	elocation-id = {236463},
	eprint = {https://www.biorxiv.org/content/early/2017/12/19/236463.full.pdf},
	journal = {bioRxiv},
	publisher = {Cold Spring Harbor Laboratory},
	title = {Content-Aware Image Restoration: Pushing the Limits of Fluorescence Microscopy},
	year = {2017},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2017/12/19/236463},
	Bdsk-Url-2 = {https://doi.org/10.1101/236463}}

@article{Wolny2020,
	abstract = {Quantitative analysis of plant and animal morphogenesis requires accurate segmentation of individual cells in volumetric images of growing organs. In the last years, deep learning has provided robust automated algorithms that approach human performance, with applications to bio-image analysis now starting to emerge. Here, we present PlantSeg, a pipeline for volumetric segmentation of plant tissues into cells. PlantSeg employs a convolutional neural network to predict cell boundaries and graph partitioning to segment cells based on the neural network predictions. PlantSeg was trained on fixed and live plant organs imaged with confocal and light sheet microscopes. PlantSeg delivers accurate results and generalizes well across different tissues, scales, and acquisition settings. We present results of PlantSeg applications in diverse developmental contexts. PlantSeg is free and open-source, with both a command line and a user-friendly graphical interface.},
	author = {Wolny, Adrian and Cerrone, Lorenzo and Vijayan, Athul and Tofanelli, Rachele and Vilches Barro, Amaya and Louveaux, Marion and Wenzl, Christian and Steigleder, Susanne and Pape, Constantin and Bailoni, Alberto and Duran-Nebreda, Salva and Bassel, George and Lohmann, Jan U. and Hamprecht, Fred A. and Schneitz, Kay and Maizel, Alexis and Kreshuk, Anna},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi = {10.1101/2020.01.17.910562},
	elocation-id = {2020.01.17.910562},
	eprint = {https://www.biorxiv.org/content/early/2020/01/18/2020.01.17.910562.full.pdf},
	journal = {bioRxiv},
	publisher = {Cold Spring Harbor Laboratory},
	title = {Accurate and Versatile 3D Segmentation of Plant Tissues at Cellular Resolution},
	year = {2020},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2020/01/18/2020.01.17.910562},
	Bdsk-Url-2 = {https://doi.org/10.1101/2020.01.17.910562}}

@article{berg2019,
	abstract = {We present ilastik, an easy-to-use interactive tool that brings machine-learning-based (bio)image analysis to end users without substantial computational expertise. It contains pre-defined workflows for image segmentation, object classification, counting and tracking. Users adapt the workflows to the problem at hand by interactively providing sparse training annotations for a nonlinear classifier. ilastik can process data in up to five dimensions (3D, time and number of channels). Its computational back end runs operations on-demand wherever possible, allowing for interactive prediction on data larger than RAM. Once the classifiers are trained, ilastik workflows can be applied to new data from the command line without further user interaction. We describe all ilastik workflows in detail, including three case studies and a discussion on the expected performance.},
	author = {Berg, Stuart and Kutra, Dominik and Kroeger, Thorben and Straehle, Christoph N. and Kausler, Bernhard X. and Haubold, Carsten and Schiegg, Martin and Ales, Janez and Beier, Thorsten and Rudy, Markus and Eren, Kemal and Cervantes, Jaime I. and Xu, Buote and Beuttenmueller, Fynn and Wolny, Adrian and Zhang, Chong and Koethe, Ullrich and Hamprecht, Fred A. and Kreshuk, Anna},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi = {10.1038/s41592-019-0582-9},
	issn = {1548-7105},
	journal = {Nature Methods},
	month = sep,
	title = {ilastik: interactive machine learning for (bio)image analysis},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41592-019-0582-9}}

@misc{eschweiler2018,
	archiveprefix = {arXiv},
	author = {Dennis Eschweiler and Thiago V. Spina and Rohan C. Choudhury and Elliot Meyerowitz and Alexandre Cunha and Johannes Stegmaier},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi={10.1109/isbi.2019.8759242},
	eprint = {1810.06933},
	primaryclass = {cs.CV},
	title = {CNN-based Preprocessing to Optimize Watershed-based Cell Segmentation in 3D Confocal Microscopy Images},
	year = {2018}}

@inproceedings{Beucher2018,
	author = {S. Beucher and F. Meyer},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi={10.1201/9781482277234-12},
	title = {The Morphological Approach to Segmentation: The Watershed Transformation},
	year = {2018}}

@inproceedings{krull2019,
	author = {Krull, Alexander and Buchholz, Tim-Oliver and Jug, Florian},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi={10.1109/cvpr.2019.00223},
	pages = {2129--2137},
	title = {Noise2void-learning denoising from single noisy images},
	year = {2019}}

@article{Weigert:2018ww,
	abstract = {Fluorescence microscopy is a key driver of discoveries in the life sciences, with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample. These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth. In this work we show how content-aware image restoration based on deep learning extends the range of biological phenomena observable by microscopy. We demonstrate on eight concrete examples how microscopy images can be restored even if 60-fold fewer photons are used during acquisition, how near isotropic resolution can be achieved with up to tenfold under-sampling along the axial direction, and how tubular and granular structures smaller than the diffraction limit can be resolved at 20-times-higher frame rates compared to state-of-the-art methods. All developed image restoration methods are freely available as open source software in Python, FIJI, and KNIME.},
	author = {Weigert, Martin and Schmidt, Uwe and Boothe, Tobias and M{\"u}ller, Andreas and Dibrov, Alexandr and Jain, Akanksha and Wilhelm, Benjamin and Schmidt, Deborah and Broaddus, Coleman and Culley, Si{\^a}n and Rocha-Martins, Mauricio and Segovia-Miranda, Fabi{\'a}n and Norden, Caren and Henriques, Ricardo and Zerial, Marino and Solimena, Michele and Rink, Jochen and Tomancak, Pavel and Royer, Loic and Jug, Florian and Myers, Eugene W.},
	da = {2018/12/01},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi = {10.1038/s41592-018-0216-7},
	id = {Weigert2018},
	isbn = {1548-7105},
	journal = {Nature Methods},
	number = {12},
	pages = {1090--1097},
	title = {Content-aware image restoration: pushing the limits of fluorescence microscopy},
	ty = {JOUR},
	volume = {15},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41592-018-0216-7}}

@article{Rasse2020,
	abstract = {Various pre-trained deep learning models for the segmentation of bioimages have been made available as developer-to-end-user solutions. They are optimized for ease of use and usually require neither knowledge of machine learning nor coding skills. However, individually testing these tools is tedious and success is uncertain. Here, we present the Open Segmentation Framework (OpSeF), a Python framework for deep learning-based instance segmentation. OpSeF aims at facilitating the collaboration of biomedical users with experienced image analysts. It builds on the analysts' knowledge in Python, machine learning, and workflow design to solve complex analysis tasks at any scale in a reproducible, well-documented way. OpSeF defines standard inputs and outputs, thereby facilitating modular workflow design and interoperability with other software. Users play an important role in problem definition, quality control, and manual refinement of results. OpSeF semi-automates preprocessing, convolutional neural network (CNN)-based segmentation in 2D or 3D, and postprocessing. It facilitates benchmarking of multiple models in parallel. OpSeF streamlines the optimization of parameters for pre- and postprocessing such, that an available model may frequently be used without retraining. Even if sufficiently good results are not achievable with this approach, intermediate results can inform the analysts in the selection of the most promising CNN-architecture in which the biomedical user might invest the effort of manually labeling training data. We provide Jupyter notebooks that document sample workflows based on various image collections. Analysts may find these notebooks useful to illustrate common segmentation challenges, as they prepare the advanced user for gradually taking over some of their tasks and completing their projects independently. The notebooks may also be used to explore the analysis options available within OpSeF in an interactive way and to document and share final workflows. Currently, three mechanistically distinct CNN-based segmentation methods, the U-Net implementation used in Cellprofiler 3.0, StarDist, and Cellpose have been integrated within OpSeF. The addition of new networks requires little; the addition of new models requires no coding skills. Thus, OpSeF might soon become both an interactive model repository, in which pre-trained models might be shared, evaluated, and reused with ease.},
	author = {Rasse, Tobias M. and Hollandi, R{\'e}ka and Horvath, Peter},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi = {10.3389/fbioe.2020.558880},
	issn = {2296-4185},
	journal = {Frontiers in Bioengineering and Biotechnology},
	pages = {1171},
	title = {OpSeF: Open Source Python Framework for Collaborative Instance Segmentation of Bioimages},
	volume = {8},
	year = {2020},
	Bdsk-Url-1 = {https://www.frontiersin.org/article/10.3389/fbioe.2020.558880},
	Bdsk-Url-2 = {https://doi.org/10.3389/fbioe.2020.558880}}

@article{Ulicna2020,
	abstract = {Single-cell methods are beginning to reveal the intrinsic heterogeneity in cell populations, which arises from the interplay or deterministic and stochastic processes. For example, the molecular mechanisms of cell cycle control are well characterised, yet the observed distribution of cell cycle durations in a population of cells is heterogenous. This variability may be governed either by stochastic processes, inherited in a deterministic fashion, or some combination of both. Previous studies have shown poor correlations within lineages when observing direct ancestral relationships but remain correlated with immediate relatives. However, assessing longer-range dependencies amid noisy data requires significantly more observations, and demands the development of automated procedures for lineage tree reconstruction. Here, we developed an open-source Python library, btrack, to facilitate retrieval of deep lineage information from live-cell imaging data. We acquired 3,500 hours of time-lapse microscopy data of epithelial cells in culture and used our software to extract 22,519 fully annotated single-cell trajectories. Benchmarking tests, including lineage tree reconstruction assessments, demonstrate that our approach yields high-fidelity results and achieves state-of-the-art performance without the requirement for manual curation of the tracker output data. To demonstrate the robustness of our supervision-free cell tracking pipeline, we retrieve cell cycle durations and their extended inter- and intra-generational family relationships, for up to eight generations, and up to fourth cousin relationships. The extracted lineage tree dataset represents approximately two orders of magnitude more data, and longer-range dependencies, than in previous studies of cell cycle heritability. Our results extend the range of observed correlations and suggest that strong heritable cell cycling is present. We envisage that our approach could be extended with additional live-cell reporters to provide a detailed quantitative characterisation of biochemical and mechanical origins to cycling heterogeneity in cell populations.Competing Interest StatementThe authors have declared no competing interest.},
	author = {Ulicna, Kristina and Vallardi, Giulia and Charras, Guillaume and Lowe, Alan R.},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi = {10.1101/2020.09.10.276980},
	elocation-id = {2020.09.10.276980},
	eprint = {https://www.biorxiv.org/content/early/2020/09/10/2020.09.10.276980.full.pdf},
	journal = {bioRxiv},
	publisher = {Cold Spring Harbor Laboratory},
	title = {Automated deep lineage tree analysis using a Bayesian single cell tracking approach},
	year = {2020},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2020/09/10/2020.09.10.276980},
	Bdsk-Url-2 = {https://doi.org/10.1101/2020.09.10.276980}}

@article{Tinevez2017,
	abstract = {We present TrackMate, an open source Fiji plugin for the automated, semi-automated, and manual tracking of single-particles. It offers a versatile and modular solution that works out of the box for end users, through a simple and intuitive user interface. It is also easily scriptable and adaptable, operating equally well on 1D over time, 2D over time, 3D over time, or other single and multi-channel image variants. TrackMate provides several visualization and analysis tools that aid in assessing the relevance of results. The utility of TrackMate is further enhanced through its ability to be readily customized to meet specific tracking problems. TrackMate is an extensible platform where developers can easily write their own detection, particle linking, visualization or analysis algorithms within the TrackMate environment. This evolving framework provides researchers with the opportunity to quickly develop and optimize new algorithms based on existing TrackMate modules without the need of having to write de novo user interfaces, including visualization, analysis and exporting tools. The current capabilities of TrackMate are presented in the context of three different biological problems. First, we perform Caenorhabditis-elegans lineage analysis to assess how light-induced damage during imaging impairs its early development. Our TrackMate-based lineage analysis indicates the lack of a cell-specific light-sensitive mechanism. Second, we investigate the recruitment of NEMO (NF-Œ∫B essential modulator) clusters in fibroblasts after stimulation by the cytokine IL-1 and show that photodamage can generate artifacts in the shape of TrackMate characterized movements that confuse motility analysis. Finally, we validate the use of TrackMate for quantitative lifetime analysis of clathrin-mediated endocytosis in plant cells.},
	author = {Jean-Yves Tinevez and Nick Perry and Johannes Schindelin and Genevieve M. Hoopes and Gregory D. Reynolds and Emmanuel Laplantine and Sebastian Y. Bednarek and Spencer L. Shorte and Kevin W. Eliceiri},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-23 19:31:19 +0200},
	doi = {10.1016/j.ymeth.2016.09.016},
	issn = {1046-2023},
	journal = {Methods},
	note = {Image Processing for Biologists},
	pages = {80-90},
	title = {TrackMate: An open and extensible platform for single-particle tracking},
	volume = {115},
	year = {2017},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S1046202316303346},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ymeth.2016.09.016}}

@article{Lahmann2019,
	abstract = {The balance between proliferation and differentiation of muscle stem cells is tightly controlled, ensuring the maintenance of a cellular pool needed for muscle growth and repair. We demonstrate here that the transcriptional regulator Hes1 controls the balance between proliferation and differentiation of activated muscle stem cells in both developing and regenerating muscle. We observed that Hes1 is expressed in an oscillatory manner in activated stem cells where it drives the oscillatory expression of MyoD. MyoD expression oscillates in activated muscle stem cells from postnatal and adult muscle under various conditions: when the stem cells are dispersed in culture, when they remain associated with single muscle fibers, or when they reside in muscle biopsies. Unstable MyoD oscillations and long periods of sustained MyoD expression are observed in differentiating cells. Ablation of the Hes1 oscillator in stem cells interfered with stable MyoD oscillations and led to prolonged periods of sustained MyoD expression, resulting in increased differentiation propensity. This interfered with the maintenance of activated muscle stem cells, and impaired muscle growth and repair. We conclude that oscillatory MyoD expression allows the cells to remain in an undifferentiated and proliferative state and is required for amplification of the activated stem cell pool.},
	author = {Lahmann, Ines and Br{\"o}hl, Dominique and Zyrianova, Tatiana and Isomura, Akihiro and Czajkowski, Maciej T and Kapoor, Varun and Griger, Joscha and Ruffault, Pierre-Louis and Mademtzoglou, Despoina and Zammit, Peter S and Wunderlich, Thomas and Spuler, Simone and K{\"u}hn, Ralf and Preibisch, Stephan and Wolf, Jana and Kageyama, Ryoichiro and Birchmeier, Carmen},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi = {10.1101/gad.322818.118},
	issn = {0890-9369},
	journal = {Genes &amp; development},
	month = {May},
	number = {9-10},
	pages = {524---535},
	title = {Oscillations of MyoD and Hes1 proteins regulate the maintenance of activated muscle stem cells},
	volume = {33},
	year = {2019},
	Bdsk-Url-1 = {https://europepmc.org/articles/PMC6499323},
	Bdsk-Url-2 = {https://doi.org/10.1101/gad.322818.118}}

@inproceedings{weigert2020,
	author = {Martin Weigert and Uwe Schmidt and Robert Haase and Ko Sugawara and Gene Myers},
	booktitle = {The IEEE Winter Conference on Applications of Computer Vision (WACV)},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi = {10.1109/WACV45572.2020.9093435},
	month = {March},
	title = {Star-convex Polyhedra for 3D Object Detection and Segmentation in Microscopy},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1109/WACV45572.2020.9093435}}

@inproceedings{schmidt2018,
	author = {Uwe Schmidt and Martin Weigert and Coleman Broaddus and Gene Myers},
	booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI} 2018 - 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part {II}},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	doi = {10.1007/978-3-030-00934-2_30},
	pages = {265--273},
	title = {Cell Detection with Star-Convex Polygons},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-030-00934-2_30}}

@inproceedings{Ronneberger2015,
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
	address = {Cham},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015},
	date-added = {2021-05-20 16:31:07 +0200},
	date-modified = {2021-05-20 16:31:07 +0200},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	isbn = {978-3-319-24574-4},
	pages = {234--241},
	publisher = {Springer International Publishing},
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	year = {2015}}
